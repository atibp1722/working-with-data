{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b59d83c-b49a-4064-8bc0-c2fda51f3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follows a linear model and uses it find a linaer boundary that separates the data\n",
    "# find the hyperplane such that the margin between both classes is maximised\n",
    "# components\n",
    "# linar model, cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b4110c-4d74-42fa-9c27-9cc87b941bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b080d29-117d-4eef-bc82-af804d4cd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self,learning_rate=0.01,lambda_param=0.01,n_iters=2000):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.weight=None\n",
    "        self.biass=None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        #case to deal with numbers less than 0\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        n_sample,n_features=X.shape\n",
    "        self.weight=np.zeros(n_features)\n",
    "        self.bias=0\n",
    "\n",
    "        #gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            for i,x in enumerate(X):\n",
    "                con=y_[i]*(np.dot(x,self.weight)-self.bias)>=1\n",
    "                if con:\n",
    "                    #update function\n",
    "                    self.weight-=self.learning_rate*(2*self.lambda_param*self.weight)\n",
    "                else:\n",
    "                    self.weight-=self.learning_rate*(2*self.lambda_param*self.weight-np.dot(x,y_[i]))\n",
    "                    self.bias-=self.learning_rate*y_[i]\n",
    "\n",
    "    def predict(self,X):\n",
    "        #represents the formula [w*x-b]\n",
    "        linear=np.dot(X,self.weight)-self.bias\n",
    "        return np.sign(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34811ae8-da4f-40f7-9df5-dbdeb41b86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033784b0-9fb2-4b71-8173-50671bd37329",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=datasets.make_blobs(n_samples=100,n_features=2,centers=2,cluster_std=1.05,random_state=42)\n",
    "y=np.where(y==0,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4068b5-9c12-4d77-8830-087eee18ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30936966 -0.19160607] -0.9000000000000006\n"
     ]
    }
   ],
   "source": [
    "svm1=SVM()\n",
    "\n",
    "svm1.fit(X,y)\n",
    "print(svm1.weight,svm1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54f739-55c7-43e1-9985-9711e5c9bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "\n",
    "    def get_hyperplane(x,weight,bias,offset):\n",
    "        return (-weight[0]+x+bias+offset)/weight[1]\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    plt.scatter(X[:,0],X[:,1],marker='x',c=y)\n",
    "\n",
    "    x00=np.amin(X[:,0])\n",
    "    x01=np.amax(X[:,0])\n",
    "\n",
    "    x11=get_hyperplane(x00,svm1.weight,svm1.bias,0)\n",
    "    x12=get_hyperplane(x01,svm1.weight,svm1.bias,0)\n",
    "\n",
    "    x11n=get_hyperplane(x00,svm1.weight,svm1.bias,-1)\n",
    "    x12n=get_hyperplane(x00,svm1.weight,svm1.bias,-1)\n",
    "\n",
    "    x11p=get_hyperplane(x00,svm1.weight,svm1.bias,1)\n",
    "    x12p=get_hyperplane(x00,svm1.weight,svm1.bias,1)\n",
    "\n",
    "    ax.plot([x00,x01],[x11,x12],'y--')\n",
    "    ax.plot([x00,x01],[x11n,x12n],'k')\n",
    "    ax.plot([x00,x01],[x11p,x12p],'k')\n",
    "\n",
    "    xmin=np.amin(X[:,1])\n",
    "    xmax=np.amax(X[:,1])\n",
    "    ax.set_ylim=([xmin-3,xmax+3])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d2146-e342-4124-9e4b-4e47af1114ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac88ba-c128-4f7b-8011-23a5c1a2d7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
